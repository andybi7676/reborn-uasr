{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# install required python packages\n",
    "!pip install torch numpy transformers datasets g2p_en editdistance tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import torch\n",
    "import editdistance\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoProcessor, AutoModelForPreTraining\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set card name\n",
    "upstream_model_card = \"facebook/wav2vec2-large-lv60\"\n",
    "reborn_model_card = \"andybi7676/reborn-uasr_ls100h_iter5-stage1\"\n",
    "dataset_card = \"andybi7676/reborn-uasr_librispeech-no-silence-100hr\"\n",
    "dataset_name = None\n",
    "split = \"test.clean\"\n",
    "\n",
    "# load models, processor and dataset from Hugging Face Hub\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-large-lv60\")\n",
    "upstream_model = AutoModelForPreTraining.from_pretrained(upstream_model_card)\n",
    "# load the reborn uasr model from the hub, which is composed of the segmenter and the generator\n",
    "reborn_model = AutoModel.from_pretrained(reborn_model_card, trust_remote_code=True, revision=\"main\")\n",
    "# load dataset from the hub (streaming mode supported!)\n",
    "dataset = load_dataset(dataset_card, dataset_name, split=split, streaming=True, trust_remote_code=True)\n",
    "\n",
    "# set other environment variables\n",
    "output_dir = f\"./output/librispeech\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, upstream_model, reborn_model, processor, output_dir, split=\"test\"):\n",
    "    # model eval mode and to device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    upstream_model = upstream_model.to(device)\n",
    "    reborn_model = reborn_model.to(device)\n",
    "    upstream_model.eval()\n",
    "    reborn_model.eval()\n",
    "    # perform evaluation and dump the results to the output directory\n",
    "    total_errs = 0\n",
    "    total_len = 0\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with torch.no_grad(), open(f\"{output_dir}/{split}.hyp\", \"w\") as hyp_fw, open(f\"{output_dir}/{split}.ref\", \"w\") as ref_fw:\n",
    "        for idx, sample in tqdm(enumerate(dataset), desc=f\"Generating results...\", dynamic_ncols=True):\n",
    "            audio_feats = processor(sample[\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\", sampling_rate=16_000).input_values\n",
    "            audio_feats = audio_feats.to(device)\n",
    "            \n",
    "            upstream_output = upstream_model(audio_feats, output_hidden_states=True)\n",
    "            wav2vecu_feats = upstream_output.hidden_states[15] #(B, T, C)\n",
    "            feats_padding_mask = torch.zeros(wav2vecu_feats.shape[:-1], dtype=torch.bool, device=device)\n",
    "\n",
    "            hypothesis = reborn_model.generate(wav2vecu_feats, feats_padding_mask)[0]\n",
    "            reference = sample[\"phoneme\"]\n",
    "            print(hypothesis, file=hyp_fw, flush=True)\n",
    "            print(reference, file=ref_fw, flush=True)\n",
    "            total_errs += editdistance.eval(hypothesis.split(), reference.split())\n",
    "            total_len += len(reference.split())\n",
    "\n",
    "    print(f\"\\nPER: {total_errs / total_len * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate based on the loaded components\n",
    "evaluate(dataset, upstream_model, reborn_model, processor, output_dir, split=split)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
